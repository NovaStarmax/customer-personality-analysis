# ğŸ§  Classification Ascendante HiÃ©rarchique (CAH) : MathÃ©matiques et fonctionnement

## ğŸ” Objectif

CrÃ©er une hiÃ©rarchie de clusters sans spÃ©cifier Ã  l'avance leur nombre.  
Chaque observation commence dans son propre cluster, puis des paires de clusters sont **fusionnÃ©es** progressivement selon leur **ressemblance**.

---

## âš™ï¸ Fonctionnement mathÃ©matique

### 1. Calcul des distances entre points

PremiÃ¨re Ã©tape : mesurer **Ã  quel point les points sont proches** les uns des autres.

â¡ï¸ **Distance euclidienne** (souvent utilisÃ©e) :

```math
d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
```

Cela donne une **matrice de distances** entre tous les points.

---

### 2. Fusion des clusters

On fusionne Ã  chaque Ã©tape les **deux clusters les plus proches**.

> La notion de "proximitÃ©" entre deux **groupes** dÃ©pend du **critÃ¨re de liaison** (*linkage*).

### ğŸ”— MÃ©thodes de liaison :

- **Single linkage** : plus petite distance entre deux points de deux groupes
- **Complete linkage** : plus grande distance entre deux points
- **Average linkage** : moyenne des distances
- **Ward** (le plus utilisÃ©) : minimise lâ€™**inertie intra-cluster**

---

### 3. Construction de la hiÃ©rarchie

Ã€ chaque fusion, on construit une **arborescence** (*dendrogramme*) qui montre comment les clusters se regroupent.

La fusion continue jusquâ€™Ã  ce quâ€™on ait **un seul cluster** contenant tous les points.

---

## ğŸ“‰ Fonction de Ward (cas particulier)

Lâ€™approche de **Ward** cherche Ã  **minimiser la somme des carrÃ©s des distances** Ã  lâ€™intÃ©rieur des clusters (inertie).

Ã€ chaque Ã©tape, on choisit de fusionner les deux clusters dont la fusion **augmente le moins** lâ€™inertie :

```math
\Delta E = \frac{n_A \cdot n_B}{n_A + n_B} ||C_A - C_B||^2
```

- `n_A`, `n_B` = tailles des clusters
- `C_A`, `C_B` = centres des clusters

---